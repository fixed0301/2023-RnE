{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:12:55.103360400Z",
     "start_time": "2023-11-14T04:12:55.083039800Z"
    }
   },
   "id": "91a24a48c60e7953"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 불가능 상태\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "       device = 'cuda:0'\n",
    "       print('현재 가상환경 GPU 사용 가능 상태')\n",
    "else:\n",
    "       device = 'cpu'\n",
    "       print('GPU 사용 불가능 상태')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:05:39.484615700Z",
     "start_time": "2023-11-14T04:05:39.411404400Z"
    }
   },
   "id": "2a6bb59c8c16479c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 24):\n",
    "       random.seed(seed)\n",
    "       np.random.seed(seed)\n",
    "       # torch.cuda.manual_seed(seed)\n",
    "       # torch.backends.cudnn.deterministic = True\n",
    "seed_everything()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:12:58.306581300Z",
     "start_time": "2023-11-14T04:12:58.268206100Z"
    }
   },
   "id": "18a26b6e0c9bac97"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "tot_actions = 5\n",
    "actions_name = 'backward', 'sit', 'slide', 'swing', 'walk'\n",
    "min_data_len = 45"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:05:40.899386700Z",
     "start_time": "2023-11-14T04:05:40.868023100Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "actions_csv_dir = '../csv_1031/'\n",
    "dataset = []\n",
    "\n",
    "label_mapping = {'backward': 0,\n",
    "                 'sit': 1,\n",
    "                 'slide': 2,\n",
    "                 'swing': 3,\n",
    "                 'walk' : 4\n",
    "                 }\n",
    "\n",
    "def map_action_to_label(csv_name):\n",
    "       for action, label in label_mapping.items():\n",
    "              if action in csv_name.split('_')[0]:\n",
    "                     return label\n",
    "       return -1\n",
    "\n",
    "for action_csv in os.listdir(actions_csv_dir):\n",
    "       action_df = pd.read_csv(os.path.join(actions_csv_dir, action_csv))\n",
    "       label = map_action_to_label(action_csv)\n",
    "       if label != -1:\n",
    "              for idx in range(0, len(action_df), int(min_data_len / 2)):\n",
    "                     seq_df = action_df[idx: idx + min_data_len] #길이만큼 데이터 자른 것(즉 length 만큼의 프레임)\n",
    "                     if len(seq_df) == min_data_len: # 딱 length에 개수 맞춰서 끊어서 넣으려고\n",
    "                            dataset.append({'key': label, 'value': seq_df}) # key에 slide, value에는 묶음 프레임 만큼이 담기겠네\n",
    "       #최종적으로 dataset에는 행동별로 dictionary 가 만들어져 들어간다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:05:44.957894800Z",
     "start_time": "2023-11-14T04:05:42.151288800Z"
    }
   },
   "id": "20776e1e9089a511"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nose_x', 'Nose_y', 'Nose_z', 'LEye_in_x', 'LEye_in_y', 'LEye_in_z',\n",
      "       'LEye_x', 'LEye_y', 'LEye_z', 'LEye_out_x', 'LEye_out_y', 'LEye_out_z',\n",
      "       'REye_in_x', 'REye_in_y', 'REye_in_z', 'REye_x', 'REye_y', 'REye_z',\n",
      "       'REye_out_x', 'REye_out_y', 'REye_out_z', 'LEar_x', 'LEar_y', 'LEar_z',\n",
      "       'REar_x', 'REar_y', 'REar_z', 'LMouth_x', 'LMouth_y', 'LMouth_z',\n",
      "       'RMouth_x', 'RMouth_y', 'RMouth_z', 'LShoulder_x', 'LShoulder_y',\n",
      "       'LShoulder_z', 'RShoulder_x', 'RShoulder_y', 'RShoulder_z', 'LElbow_x',\n",
      "       'LElbow_y', 'LElbow_z', 'RElbow_x', 'RElbow_y', 'RElbow_z', 'LWrist_x',\n",
      "       'LWrist_y', 'LWrist_z', 'RWrist_x', 'RWrist_y', 'RWrist_z', 'LPinky_x',\n",
      "       'LPinky_y', 'LPinky_z', 'RPinky_x', 'RPinky_y', 'RPinky_z', 'LIndex_x',\n",
      "       'LIndex_y', 'LIndex_z', 'RIndex_x', 'RIndex_y', 'RIndex_z', 'LThumb_x',\n",
      "       'LThumb_y', 'LThumb_z', 'RThumb_x', 'RThumb_y', 'RThumb_z', 'LHip_x',\n",
      "       'LHip_y', 'LHip_z', 'RHip_x', 'RHip_y', 'RHip_z', 'LKnee_x', 'LKnee_y',\n",
      "       'LKnee_z', 'RKnee_x', 'RKnee_y', 'RKnee_z', 'LAnkle_x', 'LAnkle_y',\n",
      "       'LAnkle_z', 'RAnkle_x', 'RAnkle_y', 'RAnkle_z', 'LHeel_x', 'LHeel_y',\n",
      "       'LHeel_z', 'RHeel_x', 'RHeel_y', 'RHeel_z', 'LFIndex_x', 'LFIndex_y',\n",
      "       'LFIndex_z', 'RFIndex_x', 'RFIndex_y', 'RFIndex_z'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['value'].columns) # z축 까지 99 (33 * 3)차원"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:43:22.401583600Z",
     "start_time": "2023-11-14T04:43:22.346768900Z"
    }
   },
   "id": "d656657e15c7e45f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "       def __init__(self, dataset): #모든 행동을 통합한 df가 들어가야함\n",
    "              self.x = []\n",
    "              self.y = []\n",
    "              for dic in dataset:\n",
    "                     self.y.append(dic['key']) #key 값에는 actions 들어감\n",
    "                     self.x.append(dic['value']) #action마다의 data 들어감\n",
    "\n",
    "       def __getitem__(self, index): #index는 행동의 index\n",
    "              data = self.x[index] # x에는 꺼내 쓸 (행동마다 45개 묶음프레임)의 데이터\n",
    "              label = self.y[index]\n",
    "              return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "       def __len__(self):\n",
    "              return len(self.x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:07:15.737380700Z",
     "start_time": "2023-11-14T04:07:15.660078Z"
    }
   },
   "id": "f6106f1224437afe"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664\n",
      "531, 66, 67\n"
     ]
    }
   ],
   "source": [
    "train_test_val_ratio = [0.8, 0.1, 0.1]\n",
    "print(len(dataset))\n",
    "train_len = int(len(dataset) * train_test_val_ratio[0])\n",
    "val_len = int(len(dataset) * train_test_val_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:07:23.137676700Z",
     "start_time": "2023-11-14T04:07:23.032897700Z"
    }
   },
   "id": "ba330d25c6c6f524"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "CFG = {'batch_size': 8,\n",
    "       'learning_rate': 2e-2,\n",
    "       'seed':24,\n",
    "       'epochs':50       \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T06:01:41.552644900Z",
     "start_time": "2023-11-14T06:01:41.471708800Z"
    }
   },
   "id": "14d2065c8d4dc0c6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=CFG['batch_size'])\n",
    "val_loader = DataLoader(valid_data, batch_size=CFG['batch_size'])\n",
    "test_loader = DataLoader(test_data, batch_size=CFG['batch_size'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:09:12.237092200Z",
     "start_time": "2023-11-14T04:09:12.149559400Z"
    }
   },
   "id": "9fa7ab00e37041cc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_dataset(lm_list, label_list):\n",
    "       lm_list, label_list = shuffle(lm_list, label_list, random_state=42)\n",
    "       return lm_list, label_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:14:37.344230300Z",
     "start_time": "2023-11-14T04:14:34.292534Z"
    }
   },
   "id": "c7be83410625fd04"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "       def __init__(self):\n",
    "              super(Model, self).__init__()\n",
    "              self.lstm1 = nn.LSTM(input_size=99, hidden_size=128, num_layers=1, batch_first=True) #input은  45 * 3(x, y z)\n",
    "              self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "              self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "              self.dropout1 = nn.Dropout(0, 1)\n",
    "              self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "              self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "              self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "              self.dropout2 = nn.Dropout(0, 1)\n",
    "              self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "              self.fc = nn.Linear(32, 5) #분류할 클래스 5가지\n",
    "\n",
    "       def forward(self, x):\n",
    "              x, _ = self.lstm1(x)\n",
    "              x, _ = self.lstm2(x)\n",
    "              x, _ = self.lstm3(x)\n",
    "              x = self.dropout1(x)\n",
    "              x, _ = self.lstm4(x)\n",
    "              x, _ = self.lstm5(x)\n",
    "              x, _ = self.lstm6(x)\n",
    "              x = self.dropout2(x)\n",
    "              x, _ = self.lstm7(x)\n",
    "              x = self.fc(x[:, -1, :])\n",
    "              return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T06:06:55.284010800Z",
     "start_time": "2023-11-14T06:06:55.222824800Z"
    }
   },
   "id": "d712906be6495443"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 45, 99])\n"
     ]
    }
   ],
   "source": [
    "# for data, label in test_loader:\n",
    "#        print('data:', len(data)) # 배치만큼 출력하니까 'data: 8.. '\n",
    "d = []\n",
    "l = []\n",
    "for data, label in test_loader:\n",
    "       d.append(data)\n",
    "       l.append(label)\n",
    "print(d[0].shape) # 8개 잡은 배치, 45개 seqence 길이, 99 차원"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T04:45:12.034967200Z",
     "start_time": "2023-11-14T04:45:11.977790300Z"
    }
   },
   "id": "8883e47fa66b3b43"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Long but found Int",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14296\\3802838341.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     24\u001B[0m               \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 26\u001B[1;33m               \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     27\u001B[0m               \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m               \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input, target)\u001B[0m\n\u001B[0;32m   1162\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1163\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1164\u001B[1;33m         return F.cross_entropy(input, target, weight=self.weight,\n\u001B[0m\u001B[0;32m   1165\u001B[0m                                \u001B[0mignore_index\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduction\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1166\u001B[0m                                label_smoothing=self.label_smoothing)\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001B[0m in \u001B[0;36mcross_entropy\u001B[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[0;32m   3012\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0msize_average\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mreduce\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3013\u001B[0m         \u001B[0mreduction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_get_string\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msize_average\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreduce\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3014\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_nn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcross_entropy_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0m_Reduction\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_enum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreduction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mignore_index\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_smoothing\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3015\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3016\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: expected scalar type Long but found Int"
     ]
    }
   ],
   "source": [
    "num_epochs = CFG['epochs']\n",
    "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
    "\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['learning_rate'] )\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size = 5,\n",
    "                                               gamma = 0.9) # learning rate scheduler 로 학습률 주기적 감소\n",
    "\n",
    "\n",
    "val_acc_max = 0.94\n",
    "val_loss_min = 0.2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "       train_loss_list = []\n",
    "       val_loss_list = []\n",
    "       val_acc_list = []\n",
    "       #모델 학습\n",
    "       for i, (images, targets) in enumerate(train_loader):\n",
    "              model.train()\n",
    "\n",
    "              optimizer.zero_grad()\n",
    "              outputs = model(images)\n",
    "\n",
    "              loss = criterion(outputs, targets)\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "              train_loss_list.append(loss.item())\n",
    "\n",
    "              if (i+1) % 20 == 0:\n",
    "                     print(f'Epoch: {epoch} - Loss: {loss:.6f}')\n",
    "\n",
    "       train_loss = np.mean(train_loss_list)\n",
    "\n",
    "\n",
    "       # 모델 검증\n",
    "       for i, (images, targets) in enumerate(val_loader):\n",
    "              model.eval()\n",
    "\n",
    "              with torch.no_grad():\n",
    "                     outputs = model(images)\n",
    "                     val_loss = criterion(outputs,targets)\n",
    "\n",
    "                     preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                     batch_acc = (preds==targets).float().mean() # boolean 값의 평균\n",
    "\n",
    "                     val_loss_list.append(val_loss.item())\n",
    "                     val_acc_list.append(batch_acc.item())\n",
    "\n",
    "       val_loss = np.mean(val_loss_list)\n",
    "       val_acc = np.mean(val_acc_list)\n",
    "\n",
    "\n",
    "       print(f'Epoch: {epoch} - valid Loss: {val_loss:.6f} - valid_acc : {val_acc:.6f}')\n",
    "\n",
    "\n",
    "       #val 에서의 정확도 기준 모델 저장\n",
    "       if val_acc_max < val_acc:\n",
    "              valid_acc_max = val_acc\n",
    "              best_models.append(model)\n",
    "              print('model save, model val acc : ', val_acc)\n",
    "\n",
    "       # if val_loss_min > val_loss:\n",
    "       #        val_loss_min = val_loss\n",
    "        \n",
    "lr_scheduler.step()\n",
    "print('Train finished, best_models size : ',len(best_models))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T06:07:01.424545200Z",
     "start_time": "2023-11-14T06:06:58.889752500Z"
    }
   },
   "id": "b9947d7a88e17ad6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 정확도 검증\n",
    "with torch.no_grad():\n",
    "       test_loss, test_acc = epoch(test_loader, mode='test')\n",
    "       test_acc = round(test_acc, 4)\n",
    "       test_loss = round(test_loss, 4)\n",
    "       print('Test Acc.: {}'.format(test_acc))\n",
    "       print('Test Loss: {}'.format(test_loss))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2043856aefa7c707"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
