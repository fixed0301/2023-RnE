{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11944\\2744825950.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m                 \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[1;34m'key'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'value'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mseq_df\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m# key에 slide, value에는 묶음 프레임 만큼이 담기겠네\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[1;31m#최종적으로 dataset에는 행동별로 dictionary 가 만들어져 들어간다.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "actions_csv_dir = '../landmark-csv-processed/'\n",
    "dataset = []\n",
    "actions = ['swing', 'slide', 'sit', 'lie', 'backward', 'walk']\n",
    "label_mapping = {'swing': 0,\n",
    "    'slide': 1,\n",
    "    'sit': 2,\n",
    "    'lie': 3,\n",
    "    'backward': 4,\n",
    "    'walk': 5\n",
    "}\n",
    "length = 20 # 그리고 데이터를 LSTM에 넣어야 하기 때문에 시퀀스로 묶어주어야 한다. 그 길이가 length라는 길이이고, 이 변수를 20으로 설정했다. 20의 의미는 20개의 frame을 하나의 시퀀스로 잡아서 입력으로 넣겠다는 의미이고,....\n",
    "# 영상 최소 길이로 묶어야하나? 아닌데 그냥 적당히 자르면 되겠지..근데 동작마다 끝나는 시점이 다른데 뭘로 묶냐\n",
    "def map_action_to_label(csv_name):\n",
    "    for action, label in label_mapping.items():\n",
    "        if action in csv_name:\n",
    "            return label\n",
    "    return -1\n",
    "\n",
    "for action_csv in os.listdir(actions_csv_dir):\n",
    "    action_df = pd.read_csv(os.path.join(actions_csv_dir, action_csv)) #실제로 csv가 아니라 list일걸요\n",
    "    label = map_action_to_label(action_csv)\n",
    "    if label != -1:\n",
    "        for idx in range(0, len(action_df), int(length / 2)):\n",
    "            seq_df = action_df[idx: idx + length] #길이만큼 데이터 자른 것(즉 length 만큼의 프레임)\n",
    "            if len(seq_df) == length: # 딱 length에 개수 맞춰서 끊어서 넣으려고\n",
    "                dataset.append({'key': label, 'value': seq_df}) # key에 slide, value에는 묶음 프레임 만큼이 담기겠네\n",
    "    #최종적으로 dataset에는 행동별로 dictionary 가 만들어져 들어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y', 'RShoulder_x', 'RShoulder_y',\n",
      "       'RElbow_x', 'RElbow_y', 'RWrist_x', 'RWrist_y', 'LShoulder_x',\n",
      "       'LShoulder_y', 'LElbow_x', 'LElbow_y', 'LWrist_x', 'LWrist_y',\n",
      "       'MidHip_x', 'MidHip_y', 'RHip_x', 'RHip_y', 'RKnee_x', 'RKnee_y',\n",
      "       'RAnkle_x', 'RAnkle_y', 'LHip_x', 'LHip_y', 'LKnee_x', 'LKnee_y',\n",
      "       'LAnkle_x', 'LAnkle_y', 'REye_x', 'REye_y', 'LEye_x', 'LEye_y',\n",
      "       'REar_x', 'REar_y', 'LEar_x', 'LEar_y', 'LBigToe_x', 'LBigToe_y',\n",
      "       'LSmallToe_x', 'LSmallToe_y', 'LHeel_x', 'LHeel_y', 'RBigToe_x',\n",
      "       'RBigToe_y', 'RSmallToe_x', 'RSmallToe_y', 'RHeel_x', 'RHeel_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['value'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 불가능 상태\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능 상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, seq_data): #모든 행동을 통합한 df가 들어가야함\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        for dic in seq_data:\n",
    "            self.y.append(dic['key']) #key 값에는 actions 들어감\n",
    "            self.x.append(dic['value']) #action마다의 data 들어감\n",
    "\n",
    "    def __getitem__(self, index): #index는 행동의 index\n",
    "        data = self.x[index] # x에는 꺼내 쓸 (행동마다 20개 묶음프레임)의 데이터\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "32, 4, 4\n"
     ]
    }
   ],
   "source": [
    "train_test_val_ratio = [0.8, 0.1, 0.1]\n",
    "print(len(dataset))\n",
    "train_len = int(len(dataset) * train_test_val_ratio[0])\n",
    "val_len = int(len(dataset) * train_test_val_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x00000237A1FFDE20>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8)\n",
    "val_loader = DataLoader(valid_data, batch_size=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=135, hidde_size=128, num_layers=1, batch_first=True) #input은  45 * 3(x, y z)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidde_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidde_size=512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0, 1)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidde_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidde_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidde_size=64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0, 1)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidde_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 5) #분류할 클래스 5가지\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    plt.rc('font', size=10)\n",
    "    global net, loss_fn, optim\n",
    "    net = Model().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "\n",
    "def init_log():\n",
    "    plt.rc('font', size=10)\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # train log 기록\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "\n",
    "\n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # validation log 기록\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "\n",
    "def last(log_list):\n",
    "    # 리스트 안의 마지막 숫자를 반환 -> print_log함수에서 사용\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def print_log():\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "\n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\ {:5}'.format(last(iter_log),train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    log_stack.append(log_str)\n",
    "\n",
    "    # 학습 추이 그래프 출력\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpj=99)\n",
    "    hist_fig.patch.set_facecolor('white')\n",
    "\n",
    "    # Loss Line 구성\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "\n",
    "    # ACC, Line 구성\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "\n",
    "    # 그래프 출력\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line\n",
    "    loss_axis.legend(hist_lines, [i.get_label() for i in hist_lines])\n",
    "    loss_axis.grid()\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "\n",
    "    # 텍스트 로그 출력\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))):\n",
    "        print(log_stack[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.cuda import empty_cache\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def epoch(data_loader, mode='train'):\n",
    "    global epoch_cnt\n",
    "\n",
    "    # 변수 초기화\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "    # 1 iteration 학습 알고리즘 (for문 1번 -> 1 epoch 완료)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed forward\n",
    "        if mode == 'train':\n",
    "            net.train()\n",
    "        else:\n",
    "            net.eval()\n",
    "\n",
    "        result = net(data)\n",
    "        _, out = torch.max(result, 1)\n",
    "\n",
    "        # 2.Loss 계산\n",
    "        loss = loss_fn(result, label)\n",
    "        iter_loss.append(loss.item())\n",
    "\n",
    "        # 3.역전파 학습 후 Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "\n",
    "        # 4. 정확도 계산\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label)\n",
    "        iter.acc.append(acc_partial.item)\n",
    "\n",
    "    # 역잔사 학습 후, Epoch 카운터 += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "\n",
    "    clear_memory\n",
    "\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maximum_epoch = 10\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # 에폭이 끝남음을 알림\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "# 정확도 검증\n",
    "with torch.no_grad():\n",
    "    test_loss, test_acc = epoch(test_loader, mode='test')\n",
    "    test_acc = round(test_acc, 4)\n",
    "    test_loss = round(test_loss, 4)\n",
    "    print('Test Acc.: {}'.format(test_acc))\n",
    "    print('Test Loss: {}'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 여기부터 실시간 영상 테스트\n",
    "\n",
    "interval = 1\n",
    "video_path = './tataset/day4_lstm/test_data/test_video.mp4'\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "img_list = []\n",
    "if cap.isOpened():\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            img = cv2.resize(img, (640, 640))\n",
    "            if cnt == interval:\n",
    "                img_list.append(img)\n",
    "                cnt = 0\n",
    "            cv2.imshow(video_path, img)\n",
    "            cv2.waitKey(1)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('저정된 frame의 개수: {}'.format(len(img_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 연속 시퀀스 분석\n",
    "from tqdm import tqdm\n",
    "\n",
    "net.eval()\n",
    "out_img_list = []\n",
    "dataset = []\n",
    "status = 'None'\n",
    "pose = np.pose.Pose(static_image_mode=True, model_complexity=1, enable_segmentaion=False, min_detection_confidence=0.3)\n",
    "\n",
    "print('시퀀스 데이터 분석 중...')\n",
    "xy_list_list = []\n",
    "\n",
    "if len(xy_list_list) == length:\n",
    "    dataset = []\n",
    "    dataset.append({'key': 0, 'value': xy_list_list})\n",
    "    dataset = MyDataset(dataset)\n",
    "    dataset = DataLoader(dataset)\n",
    "    xy_list_list = []\n",
    "    for data, label in dataset:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            result = net(data)\n",
    "            _, out = torch.max(result, 1)\n",
    "            if out.item() == 0:\n",
    "                status = 'Walking'\n",
    "            else:\n",
    "                status = 'Running'\n",
    "cv2.putText(img, status, (0, 50), cv2.FONT_HERSHEY_COMPLEX, 1.5, (0, 0, 255), 2)\n",
    "out_img_list.append(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
